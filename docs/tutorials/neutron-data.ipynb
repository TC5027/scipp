{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neutron Data\n",
    "\n",
    "This is the continuation from [Multi-dimensional datasets](https://scipp.readthedocs.io/en/latest/tutorials/multi-d-datasets.html) tutorial.\n",
    "Note that this notebooks requires [Mantid](https://www.mantidproject.org/Main_Page) and data files that are, e.g., contained in the [Docker](https://hub.docker.com/r/scipp/scipp-jupyter-demo) image of scipp.\n",
    "Therefore, outputs are unfortunately not available on readthedocs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipp as sc\n",
    "from scipp import Dim\n",
    "from scipp.plot import plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Nexus files\n",
    "\n",
    "Scipp does not support native loading of [Nexus](https://www.nexusformat.org/) files at this point.\n",
    "However, it can leverage Mantid to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = sc.Dataset()\n",
    "# Load only a single bank to reduce memory consumption, so we can run this on a laptop\n",
    "d[\"sample\"] = sc.neutron.load(filename='../data/PG3_4844_event.nxs', BankName='bank184', load_pulse_times=True)\n",
    "d[\"vanadium\"] = sc.neutron.load(filename='../data/PG3_4866_event.nxs', BankName='bank184', load_pulse_times=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that internally this calls `Load` or `LoadEventNexus` provided by Mantid.\n",
    "Scipp then converts from Mantid's `EventWorkspace` and `Workspace2D` to `DataArray`.\n",
    "Currently not all information from the Mantid workspaces is preserved in the data array.\n",
    "\n",
    "## Understanding the contents of the created dataset\n",
    "\n",
    "The dataset with loaded sample and vanadium data looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We give a short discussion of each of the entries to familiarize ourselves with how data from a Mantid workspace is mapped onto a data array or dataset.\n",
    "\n",
    "### Dimensions and coordinates\n",
    "\n",
    "#### Spectrum\n",
    "\n",
    "In most Mantid workspaces each spectrum corresponds to data measured at a detector pixel, i.e., at a specific position or region in space.\n",
    "If that is the case, scipp used `Dim.Spectrum` for this dimension.\n",
    "\n",
    "Note that using the generic `Dim.Spectrum` should be avoided in other cases.\n",
    "For example, after converting data to `Q` we need to avoid having \"compatible\" dimensions of a data and would use `Dim.Q`.\n",
    "The double meaning of what a \"spectrum\" actually is in Mantid is thus avoided.\n",
    "\n",
    "The spectrum dimension comes with a coordinate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.coords[Dim.Spectrum]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time-of-flight\n",
    "\n",
    "In contrast to a `EventWorkspace` in Mantid, a dataset does not necessarily come with a time-of-flight (TOF) coordinate (bin edges) on top of the TOF values for the events.\n",
    "Therefore `Dim.Tof` does not have a corresponding *dense* coordinate.\n",
    "See below for *sparse* TOF coordinates.\n",
    "\n",
    "### Labels\n",
    "\n",
    "Scipp stores auxiliary \"coordinate\" information as labels.\n",
    "Labels or coords (and not attributes) are used to ensure that information is compatible in operations involving multiple data arrays or dataset.\n",
    "\n",
    "This actually happended internally when we first loaded the files for sample and vanadium and inserted them into the same dataset:\n",
    "If the files had had different spectrum numbers or spectrum positions the insertion of the `'vanadium'` data would have failed due to incompatible coordinates or labels.\n",
    "\n",
    "#### Position\n",
    "\n",
    "Positions are an auxiliary coordinate for `Dim.Spectrum`, in other words they could be used to \"label\" the spectrum coordinate, e.g., in an a plot.\n",
    "The main purpose of storing postions as labels instead of, e.g., attributes is to ensure that operations between data with mismatching detector positions fail and thus prevent mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.labels['position']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The position coordinate stores the positions of all spectra.\n",
    "Each position is a 3-component vector (X, Y, Z)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beamline geometry\n",
    "\n",
    "Apart from positions of spectra we require additional geometry information for various components in a neutron beamline (instrument).\n",
    "This is stored in the `component_info` labels, which contain a single nested dataset.\n",
    "The contents of this dataset are not particularely easy to parse and we instead recommend the use of helper functions such as `sample_position` which will be discussed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.labels['component_info'].value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We emphazise the importance of storing this information as labels.\n",
    "This ensures that we cannot accidentally combine data obtained with, e.g., different sample positions.\n",
    "\n",
    "*Bonus note:\n",
    "If we ever* **do** *want to combine data with different samples we can either remove this information from the dataset, or change it to an* **attribute**.\n",
    "\n",
    "For convenient and standardized access, as well as access of derived information such as scattering angles, a number of helper functions is provided.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.neutron.sample_position(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.neutron.scattering_angle(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a full list of available beamline-geometry helpers please refer to the [documentation](https://scipp.readthedocs.io/en/latest/additional-modules/scipp-neutron.html#beamline-geometry)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bonus note:\n",
    " For the most part, the structure of `ComponentInfo` (and `DetectorInfo`) in Mantid is easily represented by a `Dataset`, i.e., very little change is required.\n",
    " For example, scanning is simply handled by an extra dimension of, e.g., the position and rotation variables.\n",
    " By using `Dataset` to handle this, we can use exactly the same tools and do not need to implement or learn a new API.*\n",
    "\n",
    "### Event data\n",
    "\n",
    "Neutron events are stored as **sparse data** in contrast to the regular gridded (\"dense\") data of, e.g., histogrammed data.\n",
    "See [the scipp documentation](https://scipp.readthedocs.io/en/latest/user-guide/sparse-data.html) for more information.\n",
    "\n",
    "The number of neutrons detected at each position is different and thus scipp has no fixed definition for the length of the \"sparse\" dimension.\n",
    "This looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.show(d[Dim.Spectrum, 10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data structure is to be interpreted as follows:\n",
    "\n",
    "- Each position sees a different number of events, and events arrive at random time.\n",
    "  Therefore, there is a time-of-flight for *every pixel*, for *every event*, and for *every data item* (`'vanadium'` and `'sample'`).\n",
    "  This **sparse coordinate** has the following properties:\n",
    "  - The sparse coord for `Dim.Tof` is associated with a data item and is not global for the dataset.\n",
    "  - The sparse coord for `Dim.Tof` depends on `Dim.Spectrum`.\n",
    "  - The sparse coord for `Dim.Tof` has a different length for each spectrum.\n",
    "- Extra information such as pulse times are stored as sparse labels.\n",
    "  What was said above for sparse coords also applies to sparse labels.\n",
    "  The length at each position matches the corresponding length of the sparse coordinate.\n",
    "- Values and variances are optional.\n",
    "  They would represent weight and weight uncertainties of events.\n",
    "  If they are not present an implicit weight of `1` is assumed, i.e., each coord value corresponds to a single neutron.\n",
    "\n",
    "The time-of-flight values for an individual pixel could be accessed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['sample'].coords[sc.Dim.Tof][sc.Dim.Spectrum, 10].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From events to histogram\n",
    "\n",
    "We histogram the event data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = sc.Variable([Dim.Tof], values=np.arange(1000.0, 20000.0, 50.0), unit=sc.units.us)\n",
    "d = sc.histogram(d, bins)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(d['sample'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake instrument view\n",
    "\n",
    "Just for fun, we can quickly generate a crude \"instrument view\".\n",
    "In this case this works since we have only a single panel.\n",
    "If there were multiple panels, they could be handled as an extra dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = sc.Dataset()\n",
    "# 154 and 7 are the extents of the panel\n",
    "panel['sample'] = sc.reshape(d['sample'].data, [Dim.X, Dim.Y, Dim.Tof], (154,7,379))\n",
    "panel.coords[Dim.Tof] = d.coords[Dim.Tof]\n",
    "# Note that the scale is meaningless, could use real instrument parameters\n",
    "panel.coords[Dim.X] = sc.Variable([Dim.X], values=np.arange(154))\n",
    "panel.coords[Dim.Y] = sc.Variable([Dim.Y], values=np.arange(7))\n",
    "# Move TOF slider around 12000 to see diffraction lines moving across the panel\n",
    "plot(panel[Dim.Tof, 180:260], axes=[Dim.Tof, Dim.Y, Dim.X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitors\n",
    "\n",
    "Monitors are not handled by the Mantid converter yet, but we can add some fake ones to demonstrate the versatility  of `Dataset`.\n",
    "Storing each monitor as a separate variable that contains a nested dataset gives us complete freedom an flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram-mode beam monitor\n",
    "edges = np.arange(0.0, 20000.0, 1000.0)\n",
    "counts = np.random.rand(len(edges-1))\n",
    "beam = sc.DataArray(\n",
    "    data=sc.Variable([Dim.Tof], values=counts, variances=counts, unit=sc.units.counts),\n",
    "    coords={Dim.Tof: sc.Variable([Dim.Tof], values=edges)})\n",
    "\n",
    "# Event-mode transmission monitor\n",
    "events = sc.Variable([Dim.Tof], shape=[sc.Dimensions.Sparse])\n",
    "events.values = np.random.rand(123456)\n",
    "transmission = sc.DataArray(coords={Dim.Tof: events})\n",
    "\n",
    "# Beam profile monitor\n",
    "profile = sc.DataArray(\n",
    "    data=sc.Variable([Dim.Y, Dim.X], values=np.random.rand(20, 20), unit=sc.units.counts),\n",
    "    coords={\n",
    "        Dim.X: sc.Variable([Dim.X], values=np.arange(-0.1, 0.11, 0.01)),\n",
    "        Dim.Y: sc.Variable([Dim.Y], values=np.arange(-0.1, 0.11, 0.01))\n",
    "    })\n",
    "for i in 1,2,3,4:\n",
    "    profile[Dim.X, i:-i][Dim.Y, i:-i] += 1.0 * sc.units.counts\n",
    "\n",
    "plot(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.Variable(value=transmission)\n",
    "d.labels['transmission'] = sc.Variable(value=transmission)\n",
    "d.labels['beam'] = sc.Variable(value=beam)\n",
    "d.labels['profile'] = sc.Variable(value=profile)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    " Normalize the sample data to the \"beam\" monitor.\n",
    "\n",
    " ### Solution 1\n",
    " The binning of the monitor does not match that of the data, so we need to rebin it before the division:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_over_beam = d['sample'] / sc.rebin(d.labels['beam'].value, Dim.Tof, d.coords[Dim.Tof])\n",
    "plot(sample_over_beam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is meaningless since our \"monitor\" contained just random noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = d['sample']\n",
    "temp_scan = sc.concatenate(sample, sample * (0.8 * sc.units.dimensionless), Dim.Temperature)\n",
    "temp_scan = sc.concatenate(temp_scan, temp_scan * (0.64 * sc.units.dimensionless), Dim.Temperature)\n",
    "temp_scan.coords[Dim.Temperature] = sc.Variable([Dim.Temperature], values=[4.3, 100.0, 180.0, 273.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(temp_scan[Dim.Spectrum, 20:], axes=[Dim.Tof, Dim.Temperature, Dim.Spectrum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(temp_scan[Dim.Spectrum, 500], collapse=Dim.Tof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit conversion\n",
    "\n",
    "Unit conversion is available in the `scipp.neutron` submodule.\n",
    "Converting a data array or dataset to a different unit implies changing one of the dimensions and its coordinate.\n",
    "Conversion can also be done with sparse data (events), but we are using the histogrammed data here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = sc.neutron.convert(d, Dim.Tof, Dim.DSpacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting cannot handle ragged coordinates at this point, rebin to edges of first spectrum\n",
    "d = sc.rebin(d, Dim.DSpacing, d.coords[Dim.DSpacing][Dim.Spectrum, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summing and normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed = sc.sum(d, Dim.Spectrum)\n",
    "plot(summed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "normalized = summed['sample'] / summed['vanadium']\n",
    "plot(normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 (advanced)\n",
    "\n",
    "Instead of loading only a single bank, load multiple, e.g., `bank124`, `bank144`, `bank164`, and `bank184`.\n",
    "Modify everything in this notebook to work with the new multi-bank data, obtaining a separate focussed diffraction spectrum for each bank.\n",
    "\n",
    "There is more than one option to solve this:\n",
    "1. Concatenate the loaded data into a single dataset, resulting in more or larger dimensions.\n",
    "2. Merge the loaded data into a single dataset, resulting in differently named variables for each bank.\n",
    "3. Call the existing code as-is for each bank, working, e.g., for a Python `list` of datasets.\n",
    "\n",
    "Each of the approaches has its advantages and drawbacks.\n",
    "\n",
    "Here we recommend option 1, which in itself can be implemented in one of two ways:\n",
    "- Concatenate along a new dimension (`Dim.Bank` is not supported currently, use, e.g., `Dim.Row` instead).\n",
    "- Concatenate along the existing dimension `Dim.Spectrum`.\n",
    "\n",
    "*Note: You will likely experience some small problems with plotting, in particular issues with multi-dimensional coordinates in the first case (we suggest to slice manually until this is supported), and large gaps in the second case (can be avoided by adding a helper-coordinate).*\n",
    "\n",
    "*Bonus note for option 3: Unlike Mantid workspaces, datasets can safely be used in combination with Python containers. Do not try this with workspaces, since they are entangled with the `AnalysisDataService`.*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
